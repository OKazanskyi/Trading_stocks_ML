{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Part Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_core.paths import jupyter_path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb # Our ML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689237, 62)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/oleg.kazanskyi/OneDrive - Danaher/Documents/Trading/ML_Part/EOD\")\n",
    "df_compact = pd.read_csv(\"full_cleaned_dataframe_2023.csv\")\n",
    "df_compact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compact[\"date\"] = df_compact[\"date\"].apply(pd.to_datetime, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>days_after_earnings_report</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>ROE</th>\n",
       "      <th>LTDE</th>\n",
       "      <th>DE</th>\n",
       "      <th>CR</th>\n",
       "      <th>GM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>...</th>\n",
       "      <th>stock</th>\n",
       "      <th>10YBond</th>\n",
       "      <th>10YB_MoM</th>\n",
       "      <th>10YB_YoY</th>\n",
       "      <th>10YB_30MA_Vector</th>\n",
       "      <th>10YB_200MA_Vector</th>\n",
       "      <th>10Y_Val_to_30MA</th>\n",
       "      <th>10Y_Val_to_200MA</th>\n",
       "      <th>Fed_Balance_MoM</th>\n",
       "      <th>Fed_Balance_YoY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97367</th>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.431713</td>\n",
       "      <td>0.438925</td>\n",
       "      <td>1.144434</td>\n",
       "      <td>0.492336</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>...</td>\n",
       "      <td>BRO</td>\n",
       "      <td>3.503</td>\n",
       "      <td>-8.513972</td>\n",
       "      <td>145.997191</td>\n",
       "      <td>-0.296312</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>-4.380246</td>\n",
       "      <td>3.671739</td>\n",
       "      <td>-1.107873</td>\n",
       "      <td>-1.986270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525501</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>0.019568</td>\n",
       "      <td>0.168876</td>\n",
       "      <td>0.170172</td>\n",
       "      <td>1.688038</td>\n",
       "      <td>0.168042</td>\n",
       "      <td>0.019568</td>\n",
       "      <td>...</td>\n",
       "      <td>PWR</td>\n",
       "      <td>1.055</td>\n",
       "      <td>12.834225</td>\n",
       "      <td>-33.814304</td>\n",
       "      <td>0.382336</td>\n",
       "      <td>0.264334</td>\n",
       "      <td>0.454976</td>\n",
       "      <td>24.138057</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>78.361896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421265</th>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Food, Beverage &amp; Tobacco</td>\n",
       "      <td>0.041169</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>4.851545</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.041169</td>\n",
       "      <td>...</td>\n",
       "      <td>MNST</td>\n",
       "      <td>2.009</td>\n",
       "      <td>2.709611</td>\n",
       "      <td>32.171053</td>\n",
       "      <td>0.092636</td>\n",
       "      <td>0.234198</td>\n",
       "      <td>4.983574</td>\n",
       "      <td>20.399104</td>\n",
       "      <td>0.423037</td>\n",
       "      <td>17.557578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476189</th>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.028998</td>\n",
       "      <td>1.767610</td>\n",
       "      <td>0.292602</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>...</td>\n",
       "      <td>ODFL</td>\n",
       "      <td>3.202</td>\n",
       "      <td>3.859877</td>\n",
       "      <td>37.957777</td>\n",
       "      <td>0.126701</td>\n",
       "      <td>0.079840</td>\n",
       "      <td>2.101811</td>\n",
       "      <td>8.002780</td>\n",
       "      <td>-0.775013</td>\n",
       "      <td>-6.583786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113275</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>0.170624</td>\n",
       "      <td>0.299216</td>\n",
       "      <td>1.163841</td>\n",
       "      <td>0.241851</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>...</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>2.510</td>\n",
       "      <td>-7.788391</td>\n",
       "      <td>-10.035842</td>\n",
       "      <td>-0.278266</td>\n",
       "      <td>-0.085743</td>\n",
       "      <td>-0.895086</td>\n",
       "      <td>-13.741813</td>\n",
       "      <td>-0.983271</td>\n",
       "      <td>-10.273240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335691</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals, Biotechnology &amp; Life Sciences</td>\n",
       "      <td>0.010860</td>\n",
       "      <td>1.047062</td>\n",
       "      <td>1.054949</td>\n",
       "      <td>0.935424</td>\n",
       "      <td>0.335594</td>\n",
       "      <td>0.010860</td>\n",
       "      <td>...</td>\n",
       "      <td>IQV</td>\n",
       "      <td>1.556</td>\n",
       "      <td>1.104613</td>\n",
       "      <td>86.124402</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>-0.041178</td>\n",
       "      <td>-1.231362</td>\n",
       "      <td>6.395630</td>\n",
       "      <td>1.280779</td>\n",
       "      <td>19.728724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182414</th>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment &amp; Services</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>0.432578</td>\n",
       "      <td>0.448544</td>\n",
       "      <td>1.756883</td>\n",
       "      <td>0.402206</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>...</td>\n",
       "      <td>DGX</td>\n",
       "      <td>1.635</td>\n",
       "      <td>-0.061125</td>\n",
       "      <td>164.135703</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>0.335923</td>\n",
       "      <td>2.383282</td>\n",
       "      <td>24.003670</td>\n",
       "      <td>0.481952</td>\n",
       "      <td>12.927699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16512</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Food, Beverage &amp; Tobacco</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.215306</td>\n",
       "      <td>0.292502</td>\n",
       "      <td>1.581893</td>\n",
       "      <td>0.081935</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>...</td>\n",
       "      <td>ADM</td>\n",
       "      <td>1.610</td>\n",
       "      <td>-0.739827</td>\n",
       "      <td>137.813885</td>\n",
       "      <td>-0.024704</td>\n",
       "      <td>0.302187</td>\n",
       "      <td>-0.546584</td>\n",
       "      <td>19.596894</td>\n",
       "      <td>1.056048</td>\n",
       "      <td>11.359576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417135</th>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Materials</td>\n",
       "      <td>0.018468</td>\n",
       "      <td>0.618596</td>\n",
       "      <td>0.626773</td>\n",
       "      <td>6.654524</td>\n",
       "      <td>0.283760</td>\n",
       "      <td>0.018468</td>\n",
       "      <td>...</td>\n",
       "      <td>MLM</td>\n",
       "      <td>1.449</td>\n",
       "      <td>-6.334842</td>\n",
       "      <td>53.171247</td>\n",
       "      <td>-0.211462</td>\n",
       "      <td>-0.063543</td>\n",
       "      <td>-6.386243</td>\n",
       "      <td>0.143513</td>\n",
       "      <td>1.101204</td>\n",
       "      <td>19.771617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297935</th>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment &amp; Services</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>1.895726</td>\n",
       "      <td>1.905765</td>\n",
       "      <td>1.091397</td>\n",
       "      <td>0.842067</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA</td>\n",
       "      <td>0.694</td>\n",
       "      <td>2.814815</td>\n",
       "      <td>-60.879369</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>-0.285979</td>\n",
       "      <td>1.479347</td>\n",
       "      <td>1.024135</td>\n",
       "      <td>0.767947</td>\n",
       "      <td>83.746045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  days_after_earnings_report            sector  \\\n",
       "97367  2022-12-13                        50.0        Financials   \n",
       "525501 2021-01-28                        91.0       Industrials   \n",
       "421265 2022-03-10                        14.0  Consumer Staples   \n",
       "476189 2018-10-19                        85.0       Industrials   \n",
       "113275 2019-04-04                        50.0       Real Estate   \n",
       "335691 2021-10-29                         8.0       Health Care   \n",
       "182414 2021-05-14                        22.0       Health Care   \n",
       "16512  2021-05-27                        30.0  Consumer Staples   \n",
       "417135 2021-12-02                        30.0         Materials   \n",
       "297935 2020-09-18                        58.0       Health Care   \n",
       "\n",
       "                                              industry       ROE      LTDE  \\\n",
       "97367                                        Insurance  0.011795  0.431713   \n",
       "525501                                   Capital Goods  0.019568  0.168876   \n",
       "421265                        Food, Beverage & Tobacco  0.041169  0.002446   \n",
       "476189                                  Transportation  0.049211  0.013736   \n",
       "113275                                     Real Estate  0.029264  0.170624   \n",
       "335691  Pharmaceuticals, Biotechnology & Life Sciences  0.010860  1.047062   \n",
       "182414                Health Care Equipment & Services  0.033666  0.432578   \n",
       "16512                         Food, Beverage & Tobacco  0.013384  0.215306   \n",
       "417135                                       Materials  0.018468  0.618596   \n",
       "297935                Health Care Equipment & Services  0.024965  1.895726   \n",
       "\n",
       "              DE        CR        GM       ROA  ...  stock  10YBond  \\\n",
       "97367   0.438925  1.144434  0.492336  0.011795  ...    BRO    3.503   \n",
       "525501  0.170172  1.688038  0.168042  0.019568  ...    PWR    1.055   \n",
       "421265  0.002573  4.851545  0.538636  0.041169  ...   MNST    2.009   \n",
       "476189  0.028998  1.767610  0.292602  0.049211  ...   ODFL    3.202   \n",
       "113275  0.299216  1.163841  0.241851  0.029264  ...   CBRE    2.510   \n",
       "335691  1.054949  0.935424  0.335594  0.010860  ...    IQV    1.556   \n",
       "182414  0.448544  1.756883  0.402206  0.033666  ...    DGX    1.635   \n",
       "16512   0.292502  1.581893  0.081935  0.013384  ...    ADM    1.610   \n",
       "417135  0.626773  6.654524  0.283760  0.018468  ...    MLM    1.449   \n",
       "297935  1.905765  1.091397  0.842067  0.024965  ...    HCA    0.694   \n",
       "\n",
       "         10YB_MoM    10YB_YoY  10YB_30MA_Vector  10YB_200MA_Vector  \\\n",
       "97367   -8.513972  145.997191         -0.296312           0.111849   \n",
       "525501  12.834225  -33.814304          0.382336           0.264334   \n",
       "421265   2.709611   32.171053          0.092636           0.234198   \n",
       "476189   3.859877   37.957777          0.126701           0.079840   \n",
       "113275  -7.788391  -10.035842         -0.278266          -0.085743   \n",
       "335691   1.104613   86.124402          0.035988          -0.041178   \n",
       "182414  -0.061125  164.135703         -0.002088           0.335923   \n",
       "16512   -0.739827  137.813885         -0.024704           0.302187   \n",
       "417135  -6.334842   53.171247         -0.211462          -0.063543   \n",
       "297935   2.814815  -60.879369          0.092715          -0.285979   \n",
       "\n",
       "        10Y_Val_to_30MA  10Y_Val_to_200MA  Fed_Balance_MoM  Fed_Balance_YoY  \n",
       "97367         -4.380246          3.671739        -1.107873        -1.986270  \n",
       "525501         0.454976         24.138057         0.011980        78.361896  \n",
       "421265         4.983574         20.399104         0.423037        17.557578  \n",
       "476189         2.101811          8.002780        -0.775013        -6.583786  \n",
       "113275        -0.895086        -13.741813        -0.983271       -10.273240  \n",
       "335691        -1.231362          6.395630         1.280779        19.728724  \n",
       "182414         2.383282         24.003670         0.481952        12.927699  \n",
       "16512         -0.546584         19.596894         1.056048        11.359576  \n",
       "417135        -6.386243          0.143513         1.101204        19.771617  \n",
       "297935         1.479347          1.024135         0.767947        83.746045  \n",
       "\n",
       "[10 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_compact.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_compact.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compact.sort_values(by = \"date\", ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'days_after_earnings_report', 'open', 'close', 'sector',\n",
      "       'industry', 'ROE', 'LTDE', 'DE', 'CR', 'GM', 'ROA', 'DPR',\n",
      "       'Acc_Rec_Pay_Ration', 'ES', 'DY', 'Piotroski_Score', 'PE', 'PB',\n",
      "       'PEG_Forward', 'PEG_Backwards', 'EPS_surprise', 'EPS_YoY_Growth',\n",
      "       'EPS_QoQ_frcst_diff', 'EPS_1Y_exp_Change', 'YoY_ROE', 'YoY_LTDE',\n",
      "       'YoY_DE', 'YoY_CR', 'YoY_GM', 'YoY_ROA', 'YoY_DPR', 'YoY_AR_Ration',\n",
      "       'YoY_ES', 'YoY_Piotroski', 'YoY_PE', 'YoY_PB', 'YoY_PEGF', 'YoY_PEGB',\n",
      "       'YoY_DY', 'EPS_1Y_exp_Change_QoQ', 'future_15dprice_change',\n",
      "       'future_30dprice_change', 'future_60dprice_change',\n",
      "       'future_90dprice_change', 'future_120dprice_change',\n",
      "       'future_150dprice_change', 'VIX_high', 'days_after_crisis', 'VIX_DoD',\n",
      "       'VIX_WoW', 'VIX_MoM', 'stock', '10YBond', '10YB_MoM', '10YB_YoY',\n",
      "       '10YB_30MA_Vector', '10YB_200MA_Vector', '10Y_Val_to_30MA',\n",
      "       '10Y_Val_to_200MA', 'Fed_Balance_MoM', 'Fed_Balance_YoY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_compact.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compact.drop(['close','open'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_compact[\"date\"] = df_compact[\"date\"].apply(pd.to_datetime, errors='coerce')\n",
    "df_compact = df_compact[df_compact['date']>'01/01/2020']\n",
    "df_compact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size for 15 is 643887 rows\n",
      "Test data size for 15  is 34190 rows\n",
      "Train data size for 30 is 633555 rows\n",
      "Test data size for 30  is 33919 rows\n",
      "Train data size for 60 is 613383 rows\n",
      "Test data size for 60  is 33375 rows\n",
      "Train data size for 90 is 593726 rows\n",
      "Test data size for 90  is 32833 rows\n",
      "Train data size for 120 is 573636 rows\n",
      "Test data size for 120  is 32292 rows\n",
      "Train data size for 150 is 552629 rows\n",
      "Test data size for 150  is 31751 rows\n"
     ]
    }
   ],
   "source": [
    "#df_compact[\"date\"] = df_compact[\"date\"].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "#Let's take the top 5% as the test df\n",
    "y_vals = [\"future_15dprice_change\",\"future_30dprice_change\",\"future_60dprice_change\",\"future_90dprice_change\",\"future_120dprice_change\",\"future_150dprice_change\"]\n",
    "n_days = [15,30,60,90,120,150]\n",
    "min_date_train = []\n",
    "\n",
    "test_dfs_list = []\n",
    "train_dfs_list = []\n",
    "full_dfs_list = []\n",
    "\n",
    "for i, j in enumerate(y_vals):\n",
    "    n = 5\n",
    "    num_rows = int(len(df_compact[df_compact[j].notnull()])*(n/100))\n",
    "    df_full = df_compact[df_compact[j].notnull()]\n",
    "    df_test = df_compact[df_compact[j].notnull()].iloc[:num_rows]\n",
    "    df_train = df_compact[df_compact[j].notnull()].iloc[num_rows:]\n",
    "    \n",
    "    #Let's remove the data closest to the prediction date to make it close to a real world scenario\n",
    "    max_date = df_train.date.max()\n",
    "    max_date = df_train.date.max() - timedelta(days=n_days[i])\n",
    "    max_date = max_date.strftime('%Y-%m-%d')\n",
    "    df_train = df_train[df_train.date < max_date]\n",
    "    \n",
    "    min_date_train.append(df_train.date.min())\n",
    "\n",
    "    #We can drop the date column as redundant now\n",
    "    df_train.drop('date',axis = 1, inplace = True)\n",
    "    df_test.drop('date',axis = 1, inplace = True)\n",
    "    df_full.drop('date',axis = 1, inplace = True)\n",
    "    \n",
    "    test_dfs_list.append(df_test)\n",
    "    train_dfs_list.append(df_train)\n",
    "    full_dfs_list.append(df_full)\n",
    "    \n",
    "    \n",
    "    print(f\"Train data size for {n_days[i]} is {df_train.shape[0]} rows\")\n",
    "    print(f\"Test data size for {n_days[i]}  is {df_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the simplicity of analysis we will work with one train dataframe but apply transformations to all the dataframes in the list\n",
    "df_train = train_dfs_list[0]\n",
    "\n",
    "cols_num = df_train.select_dtypes([np.number]).columns\n",
    "cols_str = df_train.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a classificator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we dealt with the numeric prediction of the stock prices movement.\n",
    "\n",
    "At the same time after seeing the results it made me rethink the purpose.\n",
    "\n",
    "I am not a trader and the model I am building doesn't have a purpose of daily stocks exchange.\n",
    "\n",
    "What I want to achieve is to find a stock that with high probability will grow in the next foreseeable future, hold it for a while and sell it with a profit.\n",
    "\n",
    "Considering this maybe we shouldn't solve the regression problem, but make it a classification problem instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it the classification problem we would need to replace all price times the prices are going up to 1 and down to zerows.\n",
    "\n",
    "At the same time I want my model to cover the risks, so let's add the risk factor of loosing a bet and make the range wider.\n",
    "We will change values to 1 when the price goes up on the level of 3rd percentile for every time range prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_15d_threshold = 4.112\n",
    "min_30d_threshold = 6.18\n",
    "min_60d_threshold = 9.25\n",
    "min_90d_threshold = 11.53\n",
    "min_120d_threshold = 13.77\n",
    "min_150d_threshold = 15.95\n",
    "\n",
    "list_of_thresholds = [min_15d_threshold,min_30d_threshold,min_60d_threshold,min_90d_threshold,min_120d_threshold,min_150d_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the changes to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_all = [\"future_15dprice_change\",\"future_30dprice_change\",\"future_60dprice_change\",\"future_90dprice_change\",\"future_120dprice_change\",\"future_150dprice_change\"]\n",
    "periods = [\"15d\",\"30d\",\"60d\",\"90d\",\"120d\",\"150d\"]\n",
    "#df_compact_reserve = df_compact.copy()\n",
    "#Creating a copy of the list with the dataframes\n",
    "full_dfs_list_copy = []\n",
    "train_dfs_list_copy = []\n",
    "test_dfs_list_copy = []\n",
    "for i, j in enumerate(targets_all):\n",
    "    full = full_dfs_list[i].copy()\n",
    "    train = train_dfs_list[i].copy()\n",
    "    test = test_dfs_list[i].copy()\n",
    "    full_dfs_list_copy.append(full)\n",
    "    train_dfs_list_copy.append(train)\n",
    "    test_dfs_list_copy.append(test)\n",
    "    \n",
    "\n",
    "for i, j in enumerate(targets_all):\n",
    "    #df_compact.loc[df_compact[j]<list_of_thresholds[i], j] = 0\n",
    "    #df_compact.loc[df_compact[j]>=list_of_thresholds[i], j] = 1\n",
    "    full_dfs_list_copy[i].loc[full_dfs_list_copy[i][j]<list_of_thresholds[i], j] = 0\n",
    "    full_dfs_list_copy[i].loc[full_dfs_list_copy[i][j]>=list_of_thresholds[i], j] = 1\n",
    "    train_dfs_list_copy[i].loc[train_dfs_list_copy[i][j]<list_of_thresholds[i], j] = 0\n",
    "    train_dfs_list_copy[i].loc[train_dfs_list_copy[i][j]>=list_of_thresholds[i], j] = 1\n",
    "    test_dfs_list_copy[i].loc[test_dfs_list_copy[i][j]<list_of_thresholds[i], j] = 0\n",
    "    test_dfs_list_copy[i].loc[test_dfs_list_copy[i][j]>=list_of_thresholds[i], j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_after_earnings_report</th>\n",
       "      <th>sector</th>\n",
       "      <th>ROE</th>\n",
       "      <th>LTDE</th>\n",
       "      <th>DE</th>\n",
       "      <th>CR</th>\n",
       "      <th>GM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>DPR</th>\n",
       "      <th>Acc_Rec_Pay_Ration</th>\n",
       "      <th>...</th>\n",
       "      <th>VIX_MoM</th>\n",
       "      <th>10YBond</th>\n",
       "      <th>10YB_MoM</th>\n",
       "      <th>10YB_YoY</th>\n",
       "      <th>10YB_30MA_Vector</th>\n",
       "      <th>10YB_200MA_Vector</th>\n",
       "      <th>10Y_Val_to_30MA</th>\n",
       "      <th>10Y_Val_to_200MA</th>\n",
       "      <th>Fed_Balance_MoM</th>\n",
       "      <th>Fed_Balance_YoY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>1.40459</td>\n",
       "      <td>1.955491</td>\n",
       "      <td>0.64013</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.218487</td>\n",
       "      <td>4.12987</td>\n",
       "      <td>...</td>\n",
       "      <td>20.800781</td>\n",
       "      <td>2.213</td>\n",
       "      <td>-5.143592</td>\n",
       "      <td>36.352434</td>\n",
       "      <td>-0.179169</td>\n",
       "      <td>-0.035393</td>\n",
       "      <td>-0.701913</td>\n",
       "      <td>-7.844555</td>\n",
       "      <td>-0.246252</td>\n",
       "      <td>-0.231934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>1.40459</td>\n",
       "      <td>1.955491</td>\n",
       "      <td>0.64013</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.218487</td>\n",
       "      <td>4.12987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.801425</td>\n",
       "      <td>2.207</td>\n",
       "      <td>-5.034423</td>\n",
       "      <td>36.571782</td>\n",
       "      <td>-0.175003</td>\n",
       "      <td>-0.034149</td>\n",
       "      <td>-0.798973</td>\n",
       "      <td>-8.100816</td>\n",
       "      <td>-0.246252</td>\n",
       "      <td>-0.231934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   days_after_earnings_report  sector       ROE      LTDE       DE        CR  \\\n",
       "0                        39.0       5  0.031115  1.168815  1.40459  1.955491   \n",
       "1                        40.0       5  0.031115  1.168815  1.40459  1.955491   \n",
       "\n",
       "        GM       ROA       DPR  Acc_Rec_Pay_Ration  ...    VIX_MoM  10YBond  \\\n",
       "0  0.64013  0.031115  0.218487             4.12987  ...  20.800781    2.213   \n",
       "1  0.64013  0.031115  0.218487             4.12987  ...  -0.801425    2.207   \n",
       "\n",
       "   10YB_MoM   10YB_YoY  10YB_30MA_Vector  10YB_200MA_Vector  10Y_Val_to_30MA  \\\n",
       "0 -5.143592  36.352434         -0.179169          -0.035393        -0.701913   \n",
       "1 -5.034423  36.571782         -0.175003          -0.034149        -0.798973   \n",
       "\n",
       "   10Y_Val_to_200MA  Fed_Balance_MoM  Fed_Balance_YoY  \n",
       "0         -7.844555        -0.246252        -0.231934  \n",
       "1         -8.100816        -0.246252        -0.231934  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(633555, 51)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sort_index(ascending = False, inplace = True)\n",
    "df_train.reset_index(inplace = True)\n",
    "df_train.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "display(df_train.head(2))\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=633555, step=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[\"future_30dprice_change\"]\n",
    "x_train = df_train.drop(\"future_30dprice_change\", axis = 1)\n",
    "x_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Fold 0 ========\n",
      "Our accuracy on the validation set is 0.7857, precision is 0.6751, and AUC is 0.7666\n",
      "Our out of fold AUC score is 0.7666 and precision is 0.6751 \n",
      "\n",
      "\n",
      "======= Fold 1 ========\n",
      "Our accuracy on the validation set is 0.7856, precision is 0.6648, and AUC is 0.7743\n",
      "Our out of fold AUC score is 0.7704 and precision is 0.6699 \n",
      "\n",
      "\n",
      "======= Fold 2 ========\n",
      "Our accuracy on the validation set is 0.7823, precision is 0.6657, and AUC is 0.7564\n",
      "Our out of fold AUC score is 0.7658 and precision is 0.6685 \n",
      "\n",
      "\n",
      "======= Fold 3 ========\n",
      "Our accuracy on the validation set is 0.7790, precision is 0.7536, and AUC is 0.8017\n",
      "Our out of fold AUC score is 0.7747 and precision is 0.6898 \n",
      "\n",
      "\n",
      "======= Fold 4 ========\n",
      "Our accuracy on the validation set is 0.7758, precision is 0.6916, and AUC is 0.7679\n",
      "Our out of fold AUC score is 0.7734 and precision is 0.6902 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train[\"future_30dprice_change\"]\n",
    "x_train = df_train.drop(\"future_30dprice_change\", axis = 1)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=30000, gap=round(11050,0))\n",
    "#tscv = TimeSeriesSplit(n_splits=5, test_size=30000, gap=round(2210,0))\n",
    "\n",
    "aucs = []\n",
    "precs = []\n",
    "\n",
    "for i, (train_index, val_idx) in enumerate(tscv.split(df_train)):\n",
    "        print(f\"======= Fold {i} ========\")\n",
    "        #print(f\"  Train: index={min(train_index)} : {max(train_index)}\")\n",
    "        #print(f\"  Test:  index={min(val_idx)} : {max(val_idx)}\")\n",
    "        \n",
    "        X_tr = x_train.loc[train_index]\n",
    "        y_tr = y_train.loc[train_index]\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(df_train[\"sector\"])\n",
    "        df_train[\"sector\"] = le.transform(df_train[\"sector\"])\n",
    "        df_test[\"sector\"] = le.transform(df_test[\"sector\"])\n",
    "\n",
    "        X_val = x_train.loc[val_idx]\n",
    "        y_val = y_train.loc[val_idx] \n",
    "\n",
    "        # Fit Model on Train\n",
    "        clf = lgb.LGBMClassifier(random_state=42,n_jobs = 5, n_estimators = 50)     \n",
    "        clf.fit(X_tr, y_tr)\n",
    "        pred = clf.predict(X_val)\n",
    "        #print(pred.sum())\n",
    "        #if pred.sum() == 0:\n",
    "            \n",
    "        pred_prob = clf.predict_proba(X_val)[:, 1]\n",
    "        acc_score = accuracy_score(y_val, pred)\n",
    "        precision = precision_score(y_val, pred, pos_label=1, average='binary')\n",
    "        auc_score = roc_auc_score(y_val, pred_prob)\n",
    "        \n",
    "        print(\n",
    "        f\"Our accuracy on the validation set is {acc_score:0.4f}, precision is {precision:0.4f}, and AUC is {auc_score:0.4f}\"\n",
    "        )\n",
    "        aucs.append(auc_score)\n",
    "        oof_auc = np.mean(aucs)\n",
    "        precs.append(precision)\n",
    "        precs_auc = np.mean(precs)\n",
    "        print(f'Our out of fold AUC score is {oof_auc:0.4f} and precision is {precs_auc:0.4f} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the x, y variables \n",
    "y_train = df_train[\"future_30dprice_change\"]\n",
    "y_test = df_test[\"future_30dprice_change\"]\n",
    "\n",
    "x_train = df_train.drop(\"future_30dprice_change\", axis = 1)\n",
    "x_test = df_test.drop(\"future_30dprice_change\", axis = 1)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(random_state=42,n_jobs = 5, n_estimators = 50)\n",
    "lgbm.fit(x_train, y_train)#, categorical_feature=['sector'])\n",
    "\n",
    "#predicting on test set\n",
    "ypred=lgbm.predict(x_test)\n",
    "ypred_prob = lgbm.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#calculating accuracy\n",
    "precision = round(precision_score(y_test, ypred, pos_label=1, average='binary'),2)\n",
    "AUC = round(roc_auc_score(y_test, ypred_prob),2)\n",
    "print(f\"Precision of prediction:{precision:0.2f}, and the AUC is: {AUC:0.2f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Predict Negative:0', 'Predict Positive:1'], \n",
    "                                 index=['Actual Negative:0', 'Actual Positive:1'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We got increase of precision from 49% in the regression model to 50% in classification model.\n",
    "I know that we are kind of comparing apples to oranges, but with a target we have in mind this is a great result without model tuning and little efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find the best timeframe to invest testing the classification for all the prediction length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_list = []\n",
    "AUC_list = []\n",
    "feature_importances = []\n",
    "list_of_classification_models = []\n",
    "list_of_test_df = []\n",
    "list_of_ypred = []\n",
    "list_of_ypred_proba = []\n",
    "\n",
    "for j, i in enumerate(targets_all):\n",
    "    remove_redundant_list = list(targets_all)\n",
    "    remove_redundant_list.remove(i)\n",
    "\n",
    "    #df_compact_temp = df_compact.drop(remove_redundant_list,axis = 1)\n",
    "    #df_compact_temp = df_compact_temp[df_compact_temp[i].notna()]\n",
    "    #df_train, df_test = train_test_split(df_compact_temp, test_size=0.2, random_state=42)\n",
    "    df_train, df_test = train_dfs_list_copy[j], test_dfs_list_copy[j]\n",
    "    df_train = df_train.drop(remove_redundant_list,axis = 1)\n",
    "    df_train = df_train[df_train[i].notna()]\n",
    "    df_test = df_test.drop(remove_redundant_list,axis = 1)\n",
    "    df_test = df_test[df_test[i].notna()]\n",
    "\n",
    "    df_train.drop([\"stock\",\"industry\",\"days_after_crisis\"], axis = 1, inplace = True)\n",
    "    df_test.drop([\"stock\",\"industry\",\"days_after_crisis\"], axis = 1, inplace = True)\n",
    "    list_of_test_df.append(df_test)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_train[\"sector\"])\n",
    "    df_train[\"sector\"] = le.transform(df_train[\"sector\"])\n",
    "    df_test[\"sector\"] = le.transform(df_test[\"sector\"])\n",
    "\n",
    "    #Creating the x, y variables \n",
    "    y_train = df_train[i]\n",
    "    y_test = df_test[i]\n",
    "\n",
    "    x_train = df_train.drop(i, axis = 1)\n",
    "    x_test = df_test.drop(i, axis = 1)\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(random_state=42,n_jobs = 5, n_estimators = 50)\n",
    "    lgbm.fit(x_train, y_train, categorical_feature=['sector'])\n",
    "    list_of_classification_models.append(lgbm)\n",
    "\n",
    "    #predicting on test set\n",
    "    ypred=lgbm.predict(x_test)\n",
    "    ypred_prob = lgbm.predict_proba(x_test)[:, 1]\n",
    "    list_of_ypred.append(ypred)\n",
    "    list_of_ypred_proba.append(ypred_prob)\n",
    "\n",
    "    #calculating accuracy\n",
    "    precision = round(precision_score(y_test, ypred, pos_label=1, average='binary'),2)\n",
    "    AUC = round(roc_auc_score(y_test, ypred_prob),2)\n",
    "    print(\"\\n\"*3+\"=\"*50+\"\\n\"+f\"Precision of prediction for {periods[j]}:{precision:0.2f}\")\n",
    "    print(\"\\n\"+f\"AUC of this classifier for {periods[j]}:{AUC:0.2f}\")\n",
    "    precisions_list.append(precision)\n",
    "    AUC_list.append(AUC)\n",
    "\n",
    "    cm = confusion_matrix(y_test, ypred)\n",
    "    cm_matrix = pd.DataFrame(data=cm, columns=['Predict Negative:0', 'Predict Positive:1'], \n",
    "                                     index=['Actual Negative:0', 'Actual Positive:1'])\n",
    "    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "    plt.show()\n",
    "    \n",
    "    feature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importances_,x_train.columns)), columns=['Value','Feature'])\n",
    "    feature_imp[\"Value, %\"] = (feature_imp['Value'] / feature_imp['Value'].sum()) * 100\n",
    "    print(feature_imp.sort_values(by='Value, %', ascending=False)[:20])\n",
    "    feature_importances.append(feature_imp[[\"Feature\", \"Value, %\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's summarize the precision level we got for every record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_list = [round(x*100,2) for x in precisions_list]\n",
    "AUC_list = [round(x*100,2) for x in AUC_list]\n",
    "\n",
    "precisions_compare_dt = {\"Precision achieved\":precisions_list,\"AUC achieved\":AUC_list}\n",
    "precisions_compare_df = pd.DataFrame(precisions_compare_dt, index = periods)\n",
    "precisions_compare_df.index.name = \"Forecasted Period, days\"\n",
    "\n",
    "print(precisions_compare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max precision we achieved is for 30days prediction timeframe and is 69%.\n",
    "\n",
    "We also need to remember that to be secure we are not predictiong when the price goes up, but when it goes up for more than 6% in case of 30 days and 4.1% in case of 15 days prediction.\n",
    "\n",
    "I trully wonder what might be the total precision if we compare it with the zero level.\n",
    "We have indexes untouched so lets compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's create a new column with the 30days prediction classifier: 0 when price dropped and 1 when it's increased.\n",
    "df_30d_train = train_dfs_list[1]\n",
    "df_30d_test = test_dfs_list[1]\n",
    "\n",
    "df_30d_train.loc[df_30d_train[\"future_30dprice_change\"]<0.1, \"30dprice_change_classification\"] = 0\n",
    "df_30d_train.loc[df_30d_train[\"future_30dprice_change\"]>=0.1, \"30dprice_change_classification\"] = 1\n",
    "df_30d_test.loc[df_30d_test[\"future_30dprice_change\"]<0.1, \"30dprice_change_classification\"] = 0\n",
    "df_30d_test.loc[df_30d_test[\"future_30dprice_change\"]>=0.1, \"30dprice_change_classification\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_30d_test.shape)\n",
    "len(list_of_ypred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's join prediction result to the test dataframe and get indexes\n",
    "df_prediction = df_30d_test.copy()\n",
    "df_prediction[\"prediction\"] = list_of_ypred[1]\n",
    "df_prediction = df_prediction[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's connect prediction result by indexes to the main dataframe\n",
    "df_30_compare =  df_30d_test[[\"future_30dprice_change\",\"30dprice_change_classification\"]]\n",
    "df_30_compare = df_30_compare.join(df_prediction, how = 'left')\n",
    "df_30_compare = df_30_compare[df_30_compare[\"prediction\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see how many negative values were really predicted as positive\n",
    "df_30_compare = df_30_compare[[\"30dprice_change_classification\",\"prediction\"]].groupby(\"30dprice_change_classification\").sum()\n",
    "df_30_compare[\"Value, %\"] = (df_30_compare['prediction'] / df_30_compare['prediction'].sum()) * 100\n",
    "df_30_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 86% PRECISION!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a great precision with a tested results.\n",
    "\n",
    "The only issue here is the number of required deals is close to 2500.\n",
    "\n",
    "The length of the dataset is about 3 months of data, that means implementing the strategy requires making about 800 deals a month.\n",
    "To make outcome feasible a minimum bet should be about 1000USD so the starting capital should be 800K USD.\n",
    "\n",
    "It is not a feasible amount for me personally.\n",
    "\n",
    "I want to find out if increasing of the threshold that our model uses to make a classification about the model, can actually reduce the number of deals and increase the precision even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to increase the threshold and check if we can get higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's join prediction result to the test dataframe and get indexes\n",
    "df_prediction = df_30d_test.copy()\n",
    "df_prediction[\"prediction\"] = list_of_ypred[1]\n",
    "df_prediction[\"prediction_proba\"] = list_of_ypred_proba[1]\n",
    "df_prediction = df_prediction[[\"prediction\",\"prediction_proba\"]]\n",
    "\n",
    "#let's connect prediction result by indexes to the main dataframe\n",
    "df_30_compare =  df_30d_test[[\"future_30dprice_change\",\"30dprice_change_classification\"]]\n",
    "df_30_compare = df_30_compare.join(df_prediction, how = 'left')\n",
    "df_30_compare = df_30_compare[df_30_compare[\"prediction\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that adds new conditinal columns to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_proba_column(dataframe, old_col, new_col, threshold):\n",
    "    dataframe.loc[dataframe[old_col] >= threshold, new_col] = 1\n",
    "    dataframe.loc[dataframe[old_col] < threshold, new_col] = 0\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_compare = add_proba_column(df_30_compare,\"prediction_proba\",\"pred_55\",0.55)\n",
    "df_30_compare = add_proba_column(df_30_compare,\"prediction_proba\",\"pred_60\",0.60)\n",
    "df_30_compare = add_proba_column(df_30_compare,\"prediction_proba\",\"pred_65\",0.65)\n",
    "df_30_compare = add_proba_column(df_30_compare,\"prediction_proba\",\"pred_70\",0.70)\n",
    "df_30_compare = add_proba_column(df_30_compare,\"prediction_proba\",\"pred_75\",0.75)\n",
    "df_30_compare = add_proba_column(df_30_compare,\"prediction_proba\",\"pred_80\",0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a function to display pivot tables based on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_precision(dataframe, real_class, prediction_class):\n",
    "    dataframe = dataframe[[real_class,prediction_class]].groupby(real_class).sum()\n",
    "    dataframe[\"Value, %\"] = (dataframe[prediction_class] / dataframe[prediction_class].sum()) * 100\n",
    "    display(dataframe)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicitons_list_str = [\"pred_55\",\"pred_60\",\"pred_65\",\"pred_70\",\"pred_75\",\"pred_80\"]\n",
    "\n",
    "for i in predicitons_list_str:\n",
    "    pivot_precision(df_30_compare, \"30dprice_change_classification\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we got 2 last options with the threshold above 75% that allow us to make it works with the much lower budgets.\n",
    "\n",
    "I will works with a model with a modified threshold at 80% level as it allows to work with about 25K USD budget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model and label encoder to the joblib files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's relearn our model based on all he data before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = []\n",
    "list_of_classification_models = []\n",
    "\n",
    "list_of_ypred = []\n",
    "list_of_ypred_proba = []\n",
    "\n",
    "for j, i in enumerate(targets_all):\n",
    "    remove_redundant_list = list(targets_all)\n",
    "    remove_redundant_list.remove(i)\n",
    "\n",
    "    df_full = full_dfs_list_copy[j]\n",
    "    df_full = df_full.drop(remove_redundant_list,axis = 1)\n",
    "    df_full = df_full[df_full[i].notna()]\n",
    "\n",
    "\n",
    "    df_full.drop([\"stock\",\"industry\",\"days_after_crisis\"], axis = 1, inplace = True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_full[\"sector\"])\n",
    "    df_full[\"sector\"] = le.transform(df_full[\"sector\"])\n",
    "\n",
    "    #Creating the x, y variables \n",
    "    y_train = df_full[i]\n",
    "    x_train = df_full.drop(i, axis = 1)\n",
    "\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(random_state=42,n_jobs = 5, n_estimators = 50)\n",
    "    lgbm.fit(x_train, y_train, categorical_feature=['sector'])\n",
    "    list_of_classification_models.append(lgbm)\n",
    "   \n",
    "    feature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importances_,x_train.columns)), columns=['Value','Feature'])\n",
    "    feature_imp[\"Value, %\"] = (feature_imp['Value'] / feature_imp['Value'].sum()) * 100\n",
    "    print(feature_imp.sort_values(by='Value, %', ascending=False)[:20])\n",
    "    feature_importances.append(feature_imp[[\"Feature\", \"Value, %\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Saving the label encoder\n",
    "filename = 'C:/Users/oleg.kazanskyi/OneDrive - Danaher/Documents/Trading/Models/label_encoder_012023.joblib'\n",
    "joblib.dump(le, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Saving the models\n",
    "for i, period in enumerate(periods):\n",
    "    folder = 'C:/Users/oleg.kazanskyi/OneDrive - Danaher/Documents/Trading/Models/'\n",
    "    full_path = os.path.join(folder,period+\"_model.joblib\")\n",
    "    joblib.dump(list_of_classification_models[i], full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
